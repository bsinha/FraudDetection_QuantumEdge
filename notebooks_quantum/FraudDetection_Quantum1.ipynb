{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60dd6021-ff61-47b9-8ba9-1a17a09d64e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fraud Detection and Prediction - Quantum\n",
    "==========================================\n",
    "\n",
    "***Quantum Models Used***\n",
    "* VQC (Variation Quantum Classifier)\n",
    "* \n",
    "\n",
    "\n",
    "**Author:** *Bipul Sinha*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066e2d4-3f1b-4f65-b7ca-1285807d3a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade imblearn qiskit-machine-learning qiskit-aer pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3000c-dde3-4e33-b850-dd0447a5399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda57c5-9c92-421a-930a-96503cffd48c",
   "metadata": {},
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae6806-ff7f-4b38-bab8-fd7706f46353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from load_dataset import read_csv_file\n",
    "df = read_csv_file('creditcardfraud.zip') # provide name of the zip file instead of csv file\n",
    "df.describe().T # Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ae85d-0a6b-41a8-bdb8-34e3aa12f372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f51124-6805-47db-acfc-a23a95b586cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2a6bd-89b5-46b1-b60e-3260892ec1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f694d1d-7152-4fa5-8d2a-5f94befb72b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cbar=True, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61049cfc-5217-4504-9011-f48fb5293aa2",
   "metadata": {},
   "source": [
    "## 1a. Understanding and evaluating data\n",
    "* Since, we are unable to see data from other than Class 0, we need data evaluation.\n",
    "* Plus, the number of instances of fraudelent data are less in numbers we need to pump-up the fraudelent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2b0fe-ef39-4ba7-a13f-5dbe1beeb2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "# Target distribution\n",
    "print('Target distribution \"1\" & \"0\" in column \"Class\", legal and fraudulent transactions, respectively, pieces')\n",
    "target_count = df['Class'].value_counts()\n",
    "print('0:', target_count[0])\n",
    "print('1:', target_count[1])\n",
    "print('Imbalance degree:', '1:', round(target_count[0] / target_count[1], 2))\n",
    "print (' ')\n",
    "print('Target distribution \"1\" & \"0\" in column \"Class\", legal and fraudulent transactions, respectively, %')\n",
    "print((df.groupby('Class')['Class'].count()/df['Class'].count())*100)\n",
    "\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (4, 3)\n",
    "target_count.plot(kind='pie', title='Distribution of target variable', legend=\"true\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588c361-940b-4b5e-bee1-ef676597a16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(25,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79436557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = list(df.columns)  # Assuming \"Class\" is not a feature\n",
    "correlations = np.abs(df.corr())  # Get absolute correlations\n",
    "strong_correlations = np.where(correlations > 0.7)  # Adjust threshold as needed\n",
    "feature_pairs = [(features[i], features[j]) for i, j in zip(*strong_correlations)]\n",
    "\n",
    "\n",
    "\n",
    "for x, y in feature_pairs:\n",
    "    plt.figure(figsize=(3,3))\n",
    "    #plt.subplots(2,2,figsize=(3,3) )\n",
    "    sns.scatterplot(x=x, y=y, hue=\"Class\", data=df, palette=\"tab10\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce058e-103b-4952-9aa1-6f028e66283b",
   "metadata": {},
   "source": [
    "# 2. Data Cleansing\n",
    "* Since, the number of instances of 0 is 284315 and for Class 1 it is mere 492, we need to resolve data imbalance. This could be done by either Over-Sampling or Under-Sampling\n",
    "* But prior to that, we need to figure out instances of duplicates and clean the data from such instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38217b2e-6162-4648-aa52-e83242648dfb",
   "metadata": {},
   "source": [
    "## Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95146e-8708-49f4-9f3d-8d791f8467ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.duplicated().any\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f84d0-a5e0-4e18-a4e7-761d4f15fbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1fda3-5590-4de4-a4eb-3d108ba95f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Solving Data Imbalance Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd3e53-8ad8-4f90-a74c-84636e59ac8e",
   "metadata": {},
   "source": [
    "### 3a. Columnar Imbalance\n",
    "- Normalization/Standardization - We can opt for either of them for Time and Amount column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd02364-fa42-40c1-8907-097910fc58f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "amount_data = df['Amount'].values\n",
    "\n",
    "# Plot histogram to visualize the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(amount_data, bins=30, kde=True, color='blue')\n",
    "\n",
    "# Fit a normal distribution to the data\n",
    "mu, sigma = stats.norm.fit(amount_data)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Amount Distribution\")\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Plot a Q-Q plot to compare against a theoretical normal distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(amount_data, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q plot of Amount\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a322e0-88b5-4366-8e06-9b2180482041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "time_data = df['Time'].values\n",
    "\n",
    "# Plot histogram to visualize the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(amount_data, bins=30, kde=True, color='blue')\n",
    "\n",
    "# Fit a normal distribution to the data\n",
    "mu, sigma = stats.norm.fit(time_data)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Time Distribution\")\n",
    "plt.xlabel(\"Time \")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Plot a Q-Q plot to compare against a theoretical normal distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "stats.probplot(time_data, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q plot of Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce79f17-3140-44bf-8af0-a2f891e3856d",
   "metadata": {},
   "source": [
    "### Normalization \n",
    "*As we can see that both Time and Amount does not have a Gaussian Distribution(Bell Curve) it will be good to perform Normalization on these fields*\n",
    "\n",
    "Steps:\n",
    "1. Get X-axis and Y-axis data\n",
    "2. Train-Test Split\n",
    "3. Sampling\n",
    "4. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856585d-6b6e-4730-9ff3-73e26c2cc1ea",
   "metadata": {},
   "source": [
    "#### i) Get X-Axis and Y-Axis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ab482-c623-4a3d-be18-fad241dcf850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taking columns v1 to v28 plus amount and remocing Class\n",
    "#x= df.iloc[:,1:29] # Remove .values to view data in tabular structure\n",
    "x= df.iloc[:,:-1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2c082-042c-4c62-a85e-e9ab8160317a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Considering class as Y attribute\n",
    "y = df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab612cf-27bc-4e56-9b0c-207a89d81cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Zero padding is to make the number of features equal to a power of 2.\n",
    "it is required for 'amplitude encoding' given below.\n",
    "'''\n",
    "num_examples, num_features = x.shape\n",
    "#print(x_train)\n",
    "print(num_examples)\n",
    "print(num_features)\n",
    "\n",
    "print(\"Log 2 = \", np.log2(num_features))\n",
    "print(\"Ceil = \", np.ceil(np.log2(num_features))) \n",
    "n = int(np.ceil(np.log2(num_features)))\n",
    "dim = 2**n\n",
    "print(f'(number of qubits, dimension of the Hilbert space) = {(n, dim)}')\n",
    "\n",
    "zeros = np.zeros((num_examples, dim-num_features))\n",
    "print(\"Zeroes = \", len(zeros))\n",
    "X = np.append(x, zeros, axis=1)\n",
    "print(\"X = \", X)\n",
    "num_examples, num_features = X.shape\n",
    "\n",
    "num_examples, num_features = X.shape   \n",
    "print(\"number of examples = \", num_examples)\n",
    "print(\"number of features = \", num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9c14f-930c-43b7-95c2-48efcd0ce8d0",
   "metadata": {},
   "source": [
    "#### ii) Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6689a-655b-4109-b686-c43e6f073621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test =  train_test_split(X,y, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(\"X-train\", len(x_train))\n",
    "print(\"X-test\", len(x_test))\n",
    "print(\"Y-train\", len(y_train))\n",
    "print(\"Y-test\", len(y_test))\n",
    "\n",
    "labels = ['Class 0', 'Class 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9245910-91b7-41e3-afba-38a18416a7b2",
   "metadata": {},
   "source": [
    "#### iii) Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d4c7c-55fe-4fba-8545-02471a6db61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Create the undersampler object\n",
    "rus = RandomUnderSampler(random_state=1)  # Set a random state for reproducibility\n",
    "\n",
    "# Fit and apply the undersampling to your data\n",
    "x_train_resampled, y_train_resampled = rus.fit_resample(x_train, y_train)\n",
    "\n",
    "x_test_resampled, y_test_resampled = rus.fit_resample(x_test, y_test)\n",
    "\n",
    "# Print the resampled data\n",
    "print(len(x_train_resampled))\n",
    "print(len(y_train_resampled))\n",
    "print(len(x_test_resampled))\n",
    "print(len(y_test_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771b9bf-b186-4d04-8dc9-284af403ed80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train_resampled).items()\n",
    "# Now, we can see that the data for both Class 0 and Clas 1 are now same. So the data is Balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364b6f1-f71f-4a1c-a997-1b75fa9085ac",
   "metadata": {},
   "source": [
    "#### iv) Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c286339-a757-4f10-bb25-3c4fbf44c318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_resampled)\n",
    "x_test_scaled = scaler.transform(x_test_resampled)\n",
    "\n",
    "print(len(x_train_scaled))\n",
    "print(len(x_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f87a5",
   "metadata": {},
   "source": [
    "# 4. Applying Quantum Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f2ecd",
   "metadata": {},
   "source": [
    "## Circuit Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f298ee4-a0ed-4616-9c12-d64cdb4cb4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "num_examples, num_features = x_train_scaled.shape\n",
    "#print(x_train)\n",
    "print(num_features)\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "#print(feature_map)\n",
    "\n",
    "#feature_map.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)\n",
    "\n",
    "feature_map.decompose().draw(output=\"text\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb20090-0ae1-4a97-bc5c-d5579ab0d780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
    "ansatz.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258b40c-00dc-40f8-9fa0-75db955da962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0f462-f887-4f34-9835-cc4a57f6d17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from apitoken import get_api_token\n",
    "token = get_api_token()\n",
    "\n",
    "service = QiskitRuntimeService(\n",
    "    channel='ibm_quantum',\n",
    "    instance='ibm-q/open/main',\n",
    "    token=token\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1800093",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd10694-e190-4613-af2a-e3a12213cd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backend = service.backend(\"ibm_brisbane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac3f6d-f801-49a2-85da-6505c45e249f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import Aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236c727-76be-41bf-8345-b82db4b7e348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "print(\"Num features :\", num_features)\n",
    "\n",
    "fm = RawFeatureVector(feature_dimension=num_features) \n",
    "fm.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d551e3-10bc-4d26-9589-065bcdbceecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "\n",
    "\n",
    "'''\n",
    "For angle encoding, num_qubits = num_features\n",
    "For amplitude encoding, num_qubits = n = np.log2(num_features)\n",
    "'''\n",
    "\n",
    "pqc = RealAmplitudes(num_qubits=n, reps=3)\n",
    "pqc.decompose().draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6b4da",
   "metadata": {},
   "source": [
    "## Model 1. VQC (Variation Quantum Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96301c49-0598-433e-aa63-733db99dab49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "import gc; gc.collect()\n",
    "\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import Sampler\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "\n",
    "optimizer = COBYLA(maxiter=150)\n",
    "sampler = Sampler()\n",
    "\n",
    "vqc = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=fm, #feature_map,\n",
    "    ansatz=pqc, #ansatx\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "   \n",
    ")\n",
    "\n",
    "# clear objective value history\n",
    "objective_func_vals = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70089bcd-24d8-4693-b89f-38049cb55ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(x_train_scaled))\n",
    "print(len(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f7653-6f75-4126-b7a2-21586c98d1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#start = time.time()\n",
    "vqc.fit(x_train_scaled, y_train_resampled)\n",
    "#elapsed = time.time() - start\n",
    "\n",
    "#print(f\"Training time: {round(elapsed)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3e9ec-c6f5-43ef-9cd9-c52bcdd10303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "y_train_pred = vqc.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04244bf5-60b8-4442-b6ad-9b0a6d34558c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = vqc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d13194",
   "metadata": {},
   "source": [
    "## Model 2. Neural Network Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24102534",
   "metadata": {},
   "source": [
    "# Analyze and Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pickleshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c597a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"sharedfile\"\n",
    "comparison_results = {}\n",
    "comparison_results.update(pickle.load(open(file_name, \"rb\")))\n",
    "#%store -r comparison_results\n",
    "#%store -r x\n",
    "print(comparison_results)\n",
    "#comparison_results = {}\n",
    "#%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533faeb",
   "metadata": {},
   "source": [
    "### Helper Report Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecfcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a9b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94062353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "136f1c55",
   "metadata": {},
   "source": [
    "# VQC Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c209591-08d8-42e5-b6b4-e33aec88412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_train, y_train_pred), \"= confusion matrix for train set \\n\")\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred), \"= confusion matrix for test set \\n \")\n",
    "print(round(roc_auc_score(y_test, y_test_pred),2), \"= roc_auc_score for test set \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results[\"VQC\"] =show_result(y_test, y_test_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab401d7",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a Pandas DataFrame\n",
    "df = pd.DataFrame(comparison_results).transpose()  # Transpose for better table view\n",
    "\n",
    "# Print the table\n",
    "print(df)\n",
    "\n",
    "# Create a bar chart for accuracy\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.bar(df.index, df[\"accuracy\"])\n",
    "plt.xlabel(\"Model Name\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb76cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qiskit v1.0.2 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
